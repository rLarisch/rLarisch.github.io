[
  {
    "objectID": "papers/Larisch2024_pre_print.html",
    "href": "papers/Larisch2024_pre_print.html",
    "title": "A systematic analysis of the joint effects of ganglion cells, lagged LGN cells, and intercortical inhibition on spatiotemporal processing and direction selectivity",
    "section": "",
    "text": "Abstract\nSimple cells in the visual cortex process spatial as well as temporal information of the visual stream and enable the perception of motion information. Previous work suggests that the direction selectivity of V1 simple cells is associated with a temporal offset in the thalamocortical input stream through lagged and non-lagged cells of the lateral geniculate nucleus (LGN), but also with intercortical inhibition. While there exists a large corpus of models for spatiotemporal receptive fields, the majority of them built-in the spatiotemporal dynamics by utilizing a combination of spatial and temporal functions and thus, do not explain the emergence of spatiotemporal dynamics on basis of network dynamics emerging in the retina and the LGN. In order to better comprehend the emergence of spatiotemporal processing and direction selectivity, we used a spiking neural network to implement the visual pathway from the retina to the primary visual cortex. By varying different functional parts in our network, we demonstrate how the direction selectivity of simple cells emerges through the interplay between two components: tuned intercortical inhibition and a temporal offset in the feedforward path through lagged LGN cells. Further, we observe that direction-selective simple cells are linked to a particular spiking pattern in a local excitatory-inhibitory circuit: If the stimulus moves in the non-preferred direction of a simple cell, inhibitory neurons with a different spatial position or tuning spike earlier, preventing the simple cell to spike. However, in the preferred direction, these inhibitory cells spike later, enabling the simple cell to spike.\nPaper is actual published as pre-print and can be found here.\n\n\nPython code on Github"
  },
  {
    "objectID": "papers/Teichmann_Larisch_2021.html",
    "href": "papers/Teichmann_Larisch_2021.html",
    "title": "Performance of biologically grounded models of the early visual system on standard object recognition tasks",
    "section": "",
    "text": "Abstract\nComputational neuroscience models of vision and neural network models for object recognition are often framed by different research agendas. Computational neuroscience mainly aims at replicating experimental data, while (artificial) neural networks target high performance on classification tasks. However, we propose that models of vision should be validated on object recognition tasks. At some point, mechanisms of realistic neuro-computational models of the visual cortex have to convince in object recognition as well.\nIn order to foster this idea, we report the recognition accuracy for two different neuro-computational models of the visual cortex on several object recognition datasets. The models were trained using unsupervised Hebbian learning rules on natural scene inputs for the emergence of receptive fields comparable to their biological counterpart. We assume that the emerged receptive fields result in a general codebook of features, which should be applicable to a variety of visual scenes.\nWe report the performances on datasets with different levels of difficulty, ranging from the simple MNIST to the more complex CIFAR-10 or ETH-80. We found that both networks show good results on simple digit recognition, comparable with previously published biologically plausible models. We also observed that our deeper layer neurons provide for naturalistic datasets a better recognition codebook. As for most datasets, recognition results of biologically grounded models are not available yet, our results provide a broad basis of performance values to compare methodologically similar models.\nPublished in Neural Netw.\nPlease cite this work as:\nTeichmann, M., Larisch, R., Hamker, F. H. (2021). “Performance of biologically grounded models of the early visual system on standard object recognition tasks.” JNeural Netw.\ndoi-Link: https://doi.org/10.1016/j.neunet.2021.08.009\n\n\nPython Code on Github"
  },
  {
    "objectID": "papers/Larisch_2019.html",
    "href": "papers/Larisch_2019.html",
    "title": "[Re] Connectivity reflects coding a model of voltage-based STDP with homeostats",
    "section": "",
    "text": "About the paper\nThis paper is published in the open-access peer-reviewed journal ReScience. The aim of the journal is to provide a place where scientists and researcher can present their reimplementation about previous published modells, to discuss difficulties in the reimplementation or the reproducing of original results (see for more information: https://peerj.com/articles/cs-142/. In the paper provides a detailed analysis of the reimplimentation of the Clopath et al. (2010) voltage-based triplet STDP rule in the neurosimulator ANNarchy. It discuss different parts of the reimplimentation by its self and why some results could not replicated 100% accuratly.\nPlease cite the article as:\nLarisch, R. 2019. [Re] Connectivity reflects coding a model of voltage-based STDP with homeostasis. ReScience C 5, 3, #2.\ndoi-Link: [10.5281/zenodo.3538217] (http://dx.doi.org/10.5281/zenodo.3538217)\nDownload the article here\nLink to the corresponding github repo"
  },
  {
    "objectID": "papers/Teichmann_Larisch_Hamker_2024.html",
    "href": "papers/Teichmann_Larisch_Hamker_2024.html",
    "title": "Robustness of Biologically Grounded Neural Networks Against Image Perturbations",
    "section": "",
    "text": "Abstract\nThe reliability of deep neural networks is critical for industrial applications as well as human safety and security. However, artificial deep neural networks have been found vulnerable to multiple kinds of natural, artificial, and adversarial image perturbations. In contrast, the human visual system has a remarkable robustness against a wide range of perturbations. At present, it is still unclear what mechanisms underlie this robustness. To better understand the robustness of biologically grounded neural networks, we evaluated two different biologically grounded neural networks of the primate visual system for their vulnerabilities to various image perturbations. We study a rate-based neural network, which utilizes Hebbian synaptic, intrinsic, and structural plasticity within a multi-layer neocortex-like architecture that includes feedforward excitation and inhibition, lateral inhibition, as well as feedback excitation and inhibition, and a spike-based neural network that focuses on a high degree of biologically plausible excitatory as well as inhibitory spike-timing-dependent plasticity. Both networks have been trained on natural scenes and have been earlier demonstrated to learn receptive fields and response properties of the visual cortex, and perform convincingly in object recognition in common computer vision benchmarks. We examine a subset of image perturbations from the corrupted MNIST dataset (MNIST-C) with the aim to test structural different perturbations. The investigated perturbations are namely Gaussian noise and blur, contrast, rotation, frost, and multi-line distractors. We applied them on the MNIST and EMNIST dataset. We report the degradation of recognition performance at different levels of perturbation intensity and indicate the improvement of the individual layers of both considered network types in comparison to the preprocessed input (LGN) as baseline.\nThis work was published in Artificial Neural Networks and Machine Learning - ICANN 2024. Lecture Notes in Computer Science, vol 15025. Springer, Cham..\nPlease cite this work as:\n‘Teichmann, M., Larisch, R., Hamker, F.H. (2024). Robustness of Biologically Grounded Neural Networks Against Image Perturbations. In: Wand, M., Malinovská, K., Schmidhuber, J., Tetko, I.V. (eds) Artificial Neural Networks and Machine Learning – ICANN 2024. ICANN 2024. Lecture Notes in Computer Science, vol 15025. Springer, Cham.’\ndoi-Link: https://doi.org/10.1007/978-3-031-72359-9_16"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "René Larisch\nBlücherstraße 19\n09126 Chemnitz\nrenelarischif@gmail.com\nrene.larisch@informatik.tu-chemnitz.de\n\n\n\n\n\n\n\n\nWork Experience\n\n\n\n\n\nScientific Assistante Professorshipof Artificial Intelligence University of Technology Chemnitz in Counterfactual Assessment and Valuation for Awareness Architecture (CAVAA)\nsince 09/2024\n\n\nScientific Assistante Professorshipof Artificial Intelligence University of Technology Chemnitz in Wissensbasierte Anomalieerkennung mittels Künstlicher Intelligenz in Kritischen Infrastrukturen(WAIKIKI)\n09/2020 - 10/2024\n\n\n\n\n\n\n\n\n\n\nEductation\n\n\n\n\n\nPhD at the Professorship of Artificial Intelligence University of Technology Chemnitz Title: The effects of inhibitory plasticity and the emerging network dynamics on processing visual information\nsince 10/2017\nExpected Graduation 02/2025\n\n\nDiploma in computer science University of Technology Chemnitz\n2008 - 2016\n\n\n\n\n\n\n\n\n\n\nTeaching Experience\n\n\n\n\n\n\nMachine Learning\nMachine Learning\n\nwinter semster 17\nwinter semster 18\n\n\n\n\n\n\n\n\n\n\nScholarshipts/Grant\n\n\n\n\n\nGrant: Landesinnovationspromotion Founded by the European Social Fund(ESF) and the Free State of Saxony\n10.2017 - 09.2020\n\n\nTravelgrant for a conference application Founded by DAAD and InProTUC\n10.2018\n\n\n\n\n\n\n\n\n\n\nSkills\n\n\n\n\n\n\nProgramming languages: Python, C++\n\n\n\n\n\nMachine learning frameworks: tensorflow, pythorch, scikit-learn"
  },
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "Papers",
    "section": "",
    "text": "A Neural Spiking Approach Compared to Deep Feedforward Networks on Stepwise Pixel Erasement\n\n\n\n\n\nContribution to the ICANN 2018 conference.\n\n\n\n\n\nSep 28, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n[Re] Connectivity reflects coding a model of voltage-based STDP with homeostats\n\n\n\n\n\nReScience about an implementation of the Clopath et al. (2010) voltage-based triplet STDP rule in ANNarchy\n\n\n\n\n\nOct 24, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nSensory coding and contrast invariance emerge from the control of plastic inhibition over emergent selectivity\n\n\n\n\n\nPaper about the influence of inhibitory plasticity on the development of a V1 L4 SNN.\n\n\n\n\n\nNov 29, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nPerformance of biologically grounded models of the early visual system on standard object recognition tasks\n\n\n\n\n\nPerformances of two biologically grounded neural networks on common object recognition tasks.\n\n\n\n\n\nDec 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Role of Feedback Inhibition for the Robustness Against Corruptions on Event-Based Data\n\n\n\n\n\nContribution to the ICANN 2023 conference.\n\n\n\n\n\nSep 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDetecting Anomalies in System Logs With a Compact Convolutional Transformer\n\n\n\n\n\nPaper about the detection of anomalies in Log-Data\n\n\n\n\n\nOct 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nA systematic analysis of the joint effects of ganglion cells, lagged LGN cells, and intercortical inhibition on spatiotemporal processing and direction selectivity\n\n\n\n\n\n- preprint -\n\n\n\n\n\nFeb 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRobustness of Biologically Grounded Neural Networks Against Image Perturbations\n\n\n\n\n\nContribution to the ICANN 2024 conference.\n\n\n\n\n\nSep 18, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "René Larisch",
    "section": "",
    "text": "Hello and welcome visitor! My name is René Larisch and I’m a PhD student at the lab of Artificial Intelligence of Prof. Dr. Fred H. Hamker at the University of Technology in Chemnitz."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "René Larisch",
    "section": "",
    "text": "Hello and welcome visitor! My name is René Larisch and I’m a PhD student at the lab of Artificial Intelligence of Prof. Dr. Fred H. Hamker at the University of Technology in Chemnitz."
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "René Larisch",
    "section": "Interests",
    "text": "Interests\nMy research interests range from the dynamics caused by inhibitory plasticity in spiking neural networks, over neuromorphic computing to transformer models in deep learning. Or as a list:\n\nRepresentation of input information in neural networks\nPlasticity and inhibition\nSpiking neural networks\nAttention-based deep learning\nNeuromorphic programming"
  },
  {
    "objectID": "conferences.html",
    "href": "conferences.html",
    "title": "Conference Contributions",
    "section": "",
    "text": "Larisch, R., Hamker F. H. 2024, Object detection with deep learning and attention feedback loops\nBernstein Conference, 2024, Frankfurt am Main, doi:10.12751/nncn.bc2024.112\nLarisch, R., Hamker, F. H. 2023, Spatiotemporal dynamics in a V1 model caused by surround delays in retinal cells\n32nd Annual Computational Neuroscience Meeting, 2023, Leipzig\nDinkelbach, H. Ü., Larisch, R., Vitay, J., Hamker, F. H. 2023 ANN-to-SNN conversion in the neural simulator ANNarchy\n32nd Annual Computational Neuroscience Meeting, 2023, Leipzig\nTeichmann, M., Larisch, R., Hamker F. H. 2022, Robustness of biologically grounded neural networks against image perturbations.\nBernstein Conference, 2022, Berlin, doi: 10.12751/nncn.bc2022.304\nSchuster, F., Larisch, R., 2022 KI-basierte Angriffserkennung: Von der Blackbox zum verständlichen System\n\n\nKraftwerkstechni­sches Kolloquium 2022, Dresden\n\nLarisch, R., Gönner, L., Teichmann, M., Hamker, F. H. 2021, Inhibitory plasticity- one mechanism to shape representational an metabolic efficiency\nBernstein Conference 2021, Berlin, doi: 10.12751/nncn.bc2021.p069\nLarisch, R., Hamker, F. H. 2020, Retinal surround delay leads to spatiotemporal behavior in the visual pathway.\nBernstein Conference, 2020, Berlin, doi: 10.12751/nncn.bc2020.0190\nLarisch, R., Gönner, L., Teichmann, M., Hamker, F. H. 2018. Voltage-based STDP and inhibitory plasticity cooperate to improve stimulus coding in a model of V1 simple-cells.\nBernstein Conference, 2018, Berlin, doi: 10.12751/nncn.bc2018.0064"
  },
  {
    "objectID": "papers/Larisch2021.html",
    "href": "papers/Larisch2021.html",
    "title": "Sensory coding and contrast invariance emerge from the control of plastic inhibition over emergent selectivity",
    "section": "",
    "text": "Abstract\nVisual stimuli are represented by a highly efficient code in the primary visual cortex, but the development of this code is still unclear. Two distinct factors control coding efficiency: Representational efficiency, which is determined by neuronal tuning diversity, and metabolic efficiency, which is influenced by neuronal gain. How these determinants of coding efficiency are shaped during development, supported by excitatory and inhibitory plasticity, is only partially understood. We investigate a fully plastic spiking network of the primary visual cortex, building on phenomenological plasticity rules. Our results suggest that inhibitory plasticity is key to the emergence of tuning diversity and accurate input encoding. We show that inhibitory feedback (random and specific) increases the metabolic efficiency by implementing a gain control mechanism. Interestingly, this led to the spontaneous emergence of contrast-invariant tuning curves. Our findings highlight that (1) interneuron plasticity is key to the development of tuning diversity and (2) that efficient sensory representations are an emergent property of the resulting network.\nPaper is published in PLoS Comput. Biol.\nPlease cite this work as:\nLarisch,R., Gönner, L., Teichmann, M., Hamker, F. H. (2021). “Sensory coding and contrast invariance emerge from the control of plastic inhibition over emergent selectivity.” PLoS Comput. Biol.\ndoi-Link: https://doi.org/10.1371/journal.pcbi.1009566\n\n\nDownload paper here\n\n\nDownload a bioRxiv pre-print here\n\n\nPython code on Github"
  },
  {
    "objectID": "papers/Larisch_2018.html",
    "href": "papers/Larisch_2018.html",
    "title": "A Neural Spiking Approach Compared to Deep Feedforward Networks on Stepwise Pixel Erasement",
    "section": "",
    "text": "Abstract\nIn real world scenarios, objects are often partially occluded. This requires a robustness for object recognition against these perturbations. Convolutional networks have shown good performances in classification tasks. The learned convolutional filters seem similar to receptive fields of simple cells found in the primary visual cortex. Alternatively, spiking neural networks are more biological plausible. We developed a two layer spiking network, trained on natural scenes with a biologically plausible learning rule. It is compared to two deep convolutional neural networks using a classification task of stepwise pixel erasement on MNIST. In comparison to these networks the spiking approach achieves good accuracy and robustness.\nThis work was published in Artificial Neural Networks and Machine Learning - ICANN 2018. - Cham : Springer International Publishing. 253-262.\nPlease cite this work as:\n‘Larisch, R., Teichmann, M., Hamker, F.H. (2018). “A Neural Spiking Approach Compared to Deep Feedforward Networks on Stepwise Pixel Erasement.” Artificial Neural Networks and Machine Learning - ICANN 2018. - Cham : Springer International Publishing. 253-262.’\ndoi-Link: http://dx.doi.org/10.1007/978-3-030-01418-6_25\n\n\nDownload an arXive pre-print here"
  },
  {
    "objectID": "papers/Larisch_Berger_Hamker_2023.html",
    "href": "papers/Larisch_Berger_Hamker_2023.html",
    "title": "Exploring the Role of Feedback Inhibition for the Robustness Against Corruptions on Event-Based Data",
    "section": "",
    "text": "Abstract\nIn event-based vision, visual information is encoded by sequential events in space and time, similar to the human visual system, where the retina emits spikes. Thus, spiking neural networks are to be preferred for processing event-based input streams. As for classical deep learning networks, spiking neural networks must be robust against different corruption or perturbations in the input data. However, corruption in event-based data has received little attention so far. According to previous studies, biologically motivated neural networks, consisting of lateral inhibition to implement a competition mechanism between the neurons, show an increase in the robustness against loss of information of input data. We here analyze the influence of inhibitory feedback on the robustness against four different types of corruption on an event-based data set. We demonstrate how a 1 : 1 ratio between feed-forward excitation and feedback inhibition increases the robustness against the loss of events, as well as against additional noisy events. Interestingly, our results show that strong feedback inhibition is a disadvantage if events in the input stream are shifted in space or in time.\nThis work was published in Artificial Neural Networks and Machine Learning - ICANN 2023. Lecture Notes in Computer Science, vol 14261. Springer, Cham..\nPlease cite this work as:\n‘Larisch, R., Berger, L., Hamker, F.H. (2023). Exploring the Role of Feedback Inhibition for the Robustness Against Corruptions on Event-Based Data. In: Iliadis, L., Papaleonidas, A., Angelov, P., Jayne, C. (eds) Artificial Neural Networks and Machine Learning – ICANN 2023. ICANN 2023. Lecture Notes in Computer Science, vol 14261. Springer, Cham.’\ndoi-Link: https://doi.org/10.1007/978-3-031-44198-1_17\n\n\nPython code on Github"
  },
  {
    "objectID": "papers/Larisch_Vitay_Hamker_2023.html",
    "href": "papers/Larisch_Vitay_Hamker_2023.html",
    "title": "Detecting Anomalies in System Logs With a Compact Convolutional Transformer",
    "section": "",
    "text": "Abstract\nComputer systems play an important role to ensure the correct functioning of critical systems such as train stations, power stations, emergency systems, and server infrastructures. To ensure the correct functioning and safety of these computer systems, the detection of abnormal system behavior is crucial. For that purpose, monitoring log data (mirroring the recent and current system status) is very commonly used. Because log data consists mainly of words and numbers, recent work used Transformer-based networks to analyze the log data and predict anomalies. Despite their success in fields such as natural language processing and computer vision, the main disadvantage of Transformers is the huge amount of trainable parameters, leading to long training times. In this work, we use a Compact Convolutional Transformer to detect anomalies in log data. Using convolutional layers leads to a much smaller number of trainable parameters and enable the processing of many consecutive log lines. We evaluate the proposed network on two standard datasets for log data anomaly detection, Blue Gene/L (BGL) and Spirit. Our results demonstrate that the combination of convolutional processing and self-attention improves the performance for anomaly detection in comparison to other self-supervised Transformer-based approaches, and is even on par with supervised approaches.\nThis work was published in IEEE Access.\nPlease cite this work as:\nR. Larisch, J. Vitay and F. H. Hamker, “Detecting Anomalies in System Logs With a Compact Convolutional Transformer,” in IEEE Access, vol. 11, pp. 113464-113479, 2023, doi: 10.1109/ACCESS.2023.3323252.\ndoi-Link: https://doi.org/10.1109/ACCESS.2023.3323252\n\n\nPython code on Github"
  }
]