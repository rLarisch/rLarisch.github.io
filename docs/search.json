[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "René Larisch",
    "section": "",
    "text": "My name is René Larisch and I’m a PhD student at the lab of Artificial Intelligence of Prof. Dr. Fred H. Hamer at the Technical University, Chemnitz."
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "René Larisch",
    "section": "Interests",
    "text": "Interests\nMy research interests range from inhibition in spiking neural networks to deep learning networks. They cover the following topics_\n\nrepresentation of input information in neural networks\nplasticity and inhibition\nspiking neural networks\nattention-based deep learning\nneuromporphic programming"
  },
  {
    "objectID": "index.html#conferences",
    "href": "index.html#conferences",
    "title": "René Larisch",
    "section": "Conferences",
    "text": "Conferences"
  },
  {
    "objectID": "index.html#teaching-experiences",
    "href": "index.html#teaching-experiences",
    "title": "René Larisch",
    "section": "Teaching experiences",
    "text": "Teaching experiences"
  },
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "Papers",
    "section": "",
    "text": "A Neural Spiking Approach Compared to Deep Feedforward Networks on Stepwise Pixel Erasement\n\n\n\n\n\nContribution to the ICANN 2018 conference.\n\n\n\n\n\n\nSep 28, 2018\n\n\n\n\n\n\n\n\nSensory coding and contrast invariance emerge from the control of plastic inhibition over emergent selectivity\n\n\n\n\n\nPaper about the influence of inhibitory plasticity on the development of a V1 L4 SNN.\n\n\n\n\n\n\nNov 29, 2021\n\n\n\n\n\n\n\n\nPerformance of biologically grounded models of the early visual system on standard object recognition tasks\n\n\n\n\n\nPerformances of two biologically grounded neural networks on common object recognition tasks.\n\n\n\n\n\n\nDec 1, 2021\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "papers/Larisch2021.html",
    "href": "papers/Larisch2021.html",
    "title": "Sensory coding and contrast invariance emerge from the control of plastic inhibition over emergent selectivity",
    "section": "",
    "text": "Abstract\nVisual stimuli are represented by a highly efficient code in the primary visual cortex, but the development of this code is still unclear. Two distinct factors control coding efficiency: Representational efficiency, which is determined by neuronal tuning diversity, and metabolic efficiency, which is influenced by neuronal gain. How these determinants of coding efficiency are shaped during development, supported by excitatory and inhibitory plasticity, is only partially understood. We investigate a fully plastic spiking network of the primary visual cortex, building on phenomenological plasticity rules. Our results suggest that inhibitory plasticity is key to the emergence of tuning diversity and accurate input encoding. We show that inhibitory feedback (random and specific) increases the metabolic efficiency by implementing a gain control mechanism. Interestingly, this led to the spontaneous emergence of contrast-invariant tuning curves. Our findings highlight that (1) interneuron plasticity is key to the development of tuning diversity and (2) that efficient sensory representations are an emergent property of the resulting network.\nPaper is published in PLoS Comput. Biol.\nPlease cite this work as:\nLarisch,R., Gönner, L., Teichmann, M., Hamker, F. H. (2021). “Sensory coding and contrast invariance emerge from the control of plastic inhibition over emergent selectivity.” PLoS Comput. Biol.\ndoi-Link: https://doi.org/10.1371/journal.pcbi.1009566\n\n\nDownload paper here\n\n\n[Download a bioRxiv pre-pring here ] (https://www.biorxiv.org/content/10.1101/2020.04.07.029157v3.full.pdf)\npaperurl: ’’"
  },
  {
    "objectID": "papers/Larisch_2018.html",
    "href": "papers/Larisch_2018.html",
    "title": "A Neural Spiking Approach Compared to Deep Feedforward Networks on Stepwise Pixel Erasement",
    "section": "",
    "text": "Abstract\nIn real world scenarios, objects are often partially occluded. This requires a robustness for object recognition against these perturbations. Convolutional networks have shown good performances in classification tasks. The learned convolutional filters seem similar to receptive fields of simple cells found in the primary visual cortex. Alternatively, spiking neural networks are more biological plausible. We developed a two layer spiking network, trained on natural scenes with a biologically plausible learning rule. It is compared to two deep convolutional neural networks using a classification task of stepwise pixel erasement on MNIST. In comparison to these networks the spiking approach achieves good accuracy and robustness.\nThis work was published in Artificial Neural Networks and Machine Learning - ICANN 2018. - Cham : Springer International Publishing. 253-262.\nPlease cite this work as:\n‘Larisch, R., Teichmann, M., Hamker, F.H. (2018). “A Neural Spiking Approach Compared to Deep Feedforward Networks on Stepwise Pixel Erasement.” Artificial Neural Networks and Machine Learning - ICANN 2018. - Cham : Springer International Publishing. 253-262.’\ndoi-Link: http://dx.doi.org/10.1007/978-3-030-01418-6_25\nDownload an arXive pre-print here"
  },
  {
    "objectID": "papers/Teichmann_Larisch_2021.html",
    "href": "papers/Teichmann_Larisch_2021.html",
    "title": "Performance of biologically grounded models of the early visual system on standard object recognition tasks",
    "section": "",
    "text": "Abstract\nComputational neuroscience models of vision and neural network models for object recognition are often framed by different research agendas. Computational neuroscience mainly aims at replicating experimental data, while (artificial) neural networks target high performance on classification tasks. However, we propose that models of vision should be validated on object recognition tasks. At some point, mechanisms of realistic neuro-computational models of the visual cortex have to convince in object recognition as well.\nIn order to foster this idea, we report the recognition accuracy for two different neuro-computational models of the visual cortex on several object recognition datasets. The models were trained using unsupervised Hebbian learning rules on natural scene inputs for the emergence of receptive fields comparable to their biological counterpart. We assume that the emerged receptive fields result in a general codebook of features, which should be applicable to a variety of visual scenes.\nWe report the performances on datasets with different levels of difficulty, ranging from the simple MNIST to the more complex CIFAR-10 or ETH-80. We found that both networks show good results on simple digit recognition, comparable with previously published biologically plausible models. We also observed that our deeper layer neurons provide for naturalistic datasets a better recognition codebook. As for most datasets, recognition results of biologically grounded models are not available yet, our results provide a broad basis of performance values to compare methodologically similar models.\nPublished in Neural Netw.\nPlease cite this work as:\nTeichmann, M., Larisch, R., Hamker, F. H. (2021). “Performance of biologically grounded models of the early visual system on standard object recognition tasks.” JNeural Netw.\ndoi-Link: https://doi.org/10.1016/j.neunet.2021.08.009"
  }
]